[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/blog-2/blog-2.html",
    "href": "posts/blog-2/blog-2.html",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "",
    "text": "This blog post analyzes fairness in loan approval processes. I first make a model given the training data and use the coefficents to create a score. I compare that score to a threshold to deterimine if the bank should or should not make the loan based on the training attributes. I find an average bank profit of 1820 after testing out different training features. Despite this being the optimal value, we find that the bank is likely to discriminate against people requesting medical loans, and people with lower incomes. Although these were not explicit features in the model, the model still learned that loaning to the above groups generated more risk that the bank wasn’t willing to take on."
  },
  {
    "objectID": "posts/blog-2/blog-2.html#abstract",
    "href": "posts/blog-2/blog-2.html#abstract",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "",
    "text": "This blog post analyzes fairness in loan approval processes. I first make a model given the training data and use the coefficents to create a score. I compare that score to a threshold to deterimine if the bank should or should not make the loan based on the training attributes. I find an average bank profit of 1820 after testing out different training features. Despite this being the optimal value, we find that the bank is likely to discriminate against people requesting medical loans, and people with lower incomes. Although these were not explicit features in the model, the model still learned that loaning to the above groups generated more risk that the bank wasn’t willing to take on."
  },
  {
    "objectID": "posts/blog-2/blog-2.html#setup",
    "href": "posts/blog-2/blog-2.html#setup",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\ndf_train[\"loan_int_rate\"]= (df_train[\"loan_int_rate\"])/100\ndf_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n0.0991\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n0.1347\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n0.0751\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n0.1287\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n0.0963\n0\n0.28\nN\n10"
  },
  {
    "objectID": "posts/blog-2/blog-2.html#explore",
    "href": "posts/blog-2/blog-2.html#explore",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "Explore",
    "text": "Explore\n\n# data display setup\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"darkgrid\")\n\n\n\ndata = df_train\n\n#Creating plot\nsns.displot(data=data, x=\"person_age\", hue=\"loan_intent\", multiple=\"stack\")\n\n# Adjusting x-axis limits\nplt.xlim(20, 60)\n\nplt.show()\n\n\n\n\n\n\n\n\nThis plot shows the relationship between a person’s age and their loan intent. We can see that the most loans are requested by people in their mid-20s, and are mostly for education, with medical aand venture also being top categories. As people get older, they are less likely to want a loan, but the education intent goes down and personal, home improvement and venture loan intents increase.\n\nsns.scatterplot(data= data, x= \"person_income\", y= \"loan_int_rate\", hue = \"loan_status\")\n\n\n\n\n\n\n\n\nFrom this graph, we can see that the people who get approved for loans often have the highest interest rates, which makes sense from the bank’s perspective. A higher interest rate means the bank is making more money, which offsets the risk they take on by offering the loan. On the other hand, It’s suprising that people with higher incomes are often not approved for loans. I would expect people with higher income to be more likely to be approved for a loan, given that they have more proof they can pay. A variable that might effect this outcome is the amount they are asking for. It’s possible that people with high incomes are asking for large loans that the bank doesn’t feel comfortable taking on."
  },
  {
    "objectID": "posts/blog-2/blog-2.html#model",
    "href": "posts/blog-2/blog-2.html#model",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "Model",
    "text": "Model\n\n# econding possible outcome variable\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf_train[\"loan_intent\"]= le.fit_transform(df_train[\"loan_intent\"]) \n\n\ndf_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\n5\nB\n1200\n0.0991\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\n1\nC\n11750\n0.1347\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\n1\nA\n10000\n0.0751\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\n3\nC\n1325\n0.1287\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\n2\nA\n15000\n0.0963\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\n#data cleaning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n#cleaning data\ndf_train= df_train.dropna()\n#df_train[\"income_for_age\"]= df_train[\"person_emp_length\"]+ df_train[\"cb_person_cred_hist_length\"]\ncols= [\"loan_amnt\", \"loan_percent_income\", \"loan_int_rate\"]\nX_train = df_train[cols]\nX_train = StandardScaler().fit_transform(X_train)  # Standardize features\ny_train = df_train[\"loan_status\"]\n\n\n\n#modeling\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\nweights= model.coef_.flatten()\nprint(weights)\n\n[-0.57454909  0.972518    0.96986884]\n\n\n\ndef linear_score(X, w):\n  \"\"\"\n  Calculates the linear score between features and weights\n  \"\"\"\n  return X@w # or np.dot(X, w)\n\ndf_train[\"score\"]= linear_score(X_train, weights)\n\ndf_train[\"score\"].head()\nprint(df_train[\"score\"].max())\nprint(df_train[\"score\"].min())\nprint(df_train[\"score\"].mean())\n\n2.0739622160477564\n-4.005907622058445\n4.538839364926149e-16"
  },
  {
    "objectID": "posts/blog-2/blog-2.html#find-a-threshold",
    "href": "posts/blog-2/blog-2.html#find-a-threshold",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "Find a Threshold",
    "text": "Find a Threshold\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n                      \nimport numpy as np\ndef profit(data, t):\n    \"\"\"\n    Calculates the profit the bank makes on a given loan\n\n    Args: \n    data: the dataframe containting the loan requesters\n    t: the threshold for accepting a loan\n\n    returns: the updated dataframe with a profit column\n    \"\"\"\n\n    #create binary yes/no values from scores based on t\n    y_pred = (data[\"score\"] &gt; t).astype(int)\n    data[\"y_pred\"]= y_pred\n    data[\"bank_profit\"] = 0.0\n    #print(y_pred, y_scores)\n    i00 = (data[\"loan_status\"] == 0)& (y_pred == 0)\n    i01 = (data[\"loan_status\"] == 0) & (y_pred == 1)\n    i10 = (data[\"loan_status\"] == 1) & (y_pred == 0)\n    i11 = (data[\"loan_status\"] == 1) &(y_pred == 1)\n    #sum up the bank profit based on the predicted values of weather or not someone will default\n    data[\"bank_profit\"][i00] = data[\"loan_amnt\"][i00] * (1 + 0.25 * data[\"loan_int_rate\"][i00]) ** 10 - data[\"loan_amnt\"][i00] # best case\n    data[\"bank_profit\"][i01] = np.nan\n    data[\"bank_profit\"][i10] = data[\"loan_amnt\"][i10] * (1 + 0.25 * data[\"loan_int_rate\"][i10]) ** 3 -1.7 * data[\"loan_amnt\"][i10] # worst case\n    data[\"bank_profit\"][i11] = np.nan\n\n    return data\n\n\nthresholds = np.linspace(-.5, 2, 101)  # Test values between -2 and 2\nbank_profits = [profit(df_train, t)[\"bank_profit\"].mean() for t in thresholds] # calculates the average profit per borrower for each t\nprint(sum(bank_profits))\n# Find the maximum profit and the best threshold\nmax_profit = max(bank_profits)\nt_star = thresholds[np.argmax(bank_profits)]\n\nprint(max_profit)\nprint(t_star)\n\nprofit(df_train, t_star).head()\n\n\n174256.1405963946\n1818.7080398370795\n0.55\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\nscore\ny_pred\nbank_profit\n\n\n\n\n1\n27\n98000\nRENT\n3.0\n1\nC\n11750\n0.1347\n0\n0.12\nY\n6\n0.498505\n0\n4613.567568\n\n\n2\n22\n36996\nRENT\n5.0\n1\nA\n10000\n0.0751\n0\n0.27\nN\n4\n0.509228\n0\n2044.334031\n\n\n3\n24\n26000\nRENT\n2.0\n3\nC\n1325\n0.1287\n1\n0.05\nN\n4\n0.422027\n0\n-795.445199\n\n\n4\n29\n53004\nMORTGAGE\n2.0\n2\nA\n15000\n0.0963\n0\n0.28\nN\n10\n0.865295\n1\nNaN\n\n\n7\n39\n43000\nMORTGAGE\n3.0\n2\nA\n6250\n0.0768\n0\n0.15\nN\n14\n-0.538177\n0\n1309.170955\n\n\n\n\n\n\n\n\n\nthresholds = np.linspace(-.5, 2, 101)\nprofits = [profit(df_train, t)[\"bank_profit\"].mean() for t in thresholds]\n\n# Find the best threshold\nbest_threshold = thresholds[np.argmax(profits)]\nbest_profit = max(profits)\n\n# Plot using Seaborn\nsns.lineplot(x=thresholds, y=profits)\n\n# Add vertical line for the best threshold\nplt.axvline(best_threshold, linestyle=\"--\", color=\"gray\")\n\n# Labels and title\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Expected Profit per Borrower\")\nplt.title(f\"Max Profit: {best_profit:.3f} at Threshold {best_threshold:.3f}\")\n\nplt.show()\n\n\n\n\n\n\n\n\nHere we see that the optimal value for t= 0.55, with max profit of $1820 per borrower. We can see a steady climb up to the threshold with increasing values of t and then a sharper droppoff as the bank takes on large sums of risk. An addition to the model would be evaluating the opportunity cost of rejecting a loan with someone who would pay it back to better reflect the downside to being risk-adverse"
  },
  {
    "objectID": "posts/blog-2/blog-2.html#evaluate-from-the-banks-perspective",
    "href": "posts/blog-2/blog-2.html#evaluate-from-the-banks-perspective",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "Evaluate from the bank’s perspective",
    "text": "Evaluate from the bank’s perspective\n\n# Setup for test\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\ndf_test[\"loan_int_rate\"]= (df_test[\"loan_int_rate\"])/100\ndf_test[\"loan_intent_num\"]= le.fit_transform(df_test[\"loan_intent\"])\ndf_test= df_test.dropna()\n\n\nX_test= df_test[cols]\nX_test = StandardScaler().fit_transform(X_test)\ny_test= df_test[\"loan_status\"]\ndf_test[\"score\"]= linear_score(X_test, weights)\nprint(t_star)\nprint(profit(df_test, t_star)[\"bank_profit\"].mean().astype(int))\ndf_test[\"score\"].head()\n\n0.55\n1614\n\n\n0    0.786480\n1    0.686157\n2    0.069078\n3    0.526613\n4    0.879793\nName: score, dtype: float64\n\n\nI’m getting a similar average bank profit with the testing data, which makes sense, but at $1615, it is 200 dollars lower than that of the training data. Maybe the characteristics in the training data I used aren’t as apparent in the testing data, and maybe different patterns or stronger. It could also be that the testing data has less opporunity for bank income in the first place."
  },
  {
    "objectID": "posts/blog-2/blog-2.html#evaluate-from-the-borrowers-perspective",
    "href": "posts/blog-2/blog-2.html#evaluate-from-the-borrowers-perspective",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "Evaluate from the borrower’s perspective",
    "text": "Evaluate from the borrower’s perspective\n\nage_groups = [18, 25, 35, 50, 65, 100]\ndf_test[\"age_group\"] = pd.cut(df_test[\"person_age\"], bins=age_groups, labels=[\"18-25\", \"26-35\", \"36-50\", \"51-65\", \"65+\"])\ndf_test.groupby(\"age_group\")[[\"y_pred\", \"loan_status\"]].mean().reset_index()\n\n\n\n\n\n\n\n\nage_group\ny_pred\nloan_status\n\n\n\n\n0\n18-25\n0.349300\n0.231024\n\n\n1\n26-35\n0.313725\n0.216938\n\n\n2\n36-50\n0.308362\n0.202091\n\n\n3\n51-65\n0.292683\n0.317073\n\n\n4\n65+\n0.200000\n0.200000\n\n\n\n\n\n\n\nYounger people are less likley to recieve loans, and they are also the second most likely group to default on their loans. Surpisingly, people aged 51-65 are more likely to recieve loans, but also the most likely to default on them. Given their age, I would assume that they get the benefit of the doubt and are given loans more frequently.\n\ndf_test.groupby(\"loan_intent\")[[\"y_pred\", \"loan_status\"]].mean().reset_index()\n\n\n\n\n\n\n\n\nloan_intent\ny_pred\nloan_status\n\n\n\n\n0\nDEBTCONSOLIDATION\n0.344027\n0.287611\n\n\n1\nEDUCATION\n0.315476\n0.167517\n\n\n2\nHOMEIMPROVEMENT\n0.324675\n0.250000\n\n\n3\nMEDICAL\n0.345760\n0.284250\n\n\n4\nPERSONAL\n0.335671\n0.220441\n\n\n5\nVENTURE\n0.313278\n0.146266\n\n\n\n\n\n\n\nMedical loans aren’t super likely to given, probably because they have a higher default rate of 28%. Venture and education are most likely to be given, and both have low default rates. This is probably because both loans are seen as an investment into future great economic opportunity.\n\nincome_bins = [0, 30000, 60000, 100000, np.inf]\nincome_labels = [\"&lt;30K\", \"30K-60K\", \"60K-100K\", \"100K+\"]\ndf_test[\"income_group\"] = pd.cut(df_test[\"person_income\"], bins=income_bins, labels=income_labels)\n\ndf_test.groupby(\"income_group\")[[\"y_pred\", \"loan_status\"]].mean().reset_index()\n\n\n\n\n\n\n\n\nincome_group\ny_pred\nloan_status\n\n\n\n\n0\n&lt;30K\n0.640523\n0.460131\n\n\n1\n30K-60K\n0.403900\n0.242340\n\n\n2\n60K-100K\n0.198002\n0.136898\n\n\n3\n100K+\n0.063915\n0.110519\n\n\n\n\n\n\n\nAs income increases, people are more likely to be approved for loans and less likely to default. This makes sense, as people with greater income have more stability, and are more likely to have the capital to pay off a loan, even if their purpose in getting it didn’t pay off."
  },
  {
    "objectID": "posts/blog-2/blog-2.html#discussion",
    "href": "posts/blog-2/blog-2.html#discussion",
    "title": "Blog Two - Design and Impact of Automated Decision Systems",
    "section": "Discussion",
    "text": "Discussion\nFairness means that people are given just treatment without discrimination or bias. Therefore, this blog post analyzes questions of fairness by looking at what makes someone elligible for a loan. One of the results was that people requesting medical loans are more likely to default, thereby reducing their chances of recieving the loan. I think that this is unfair, but not from the bank’s perspecitive. As a player in a capitalist society, the bank’s responsibility is to increase profit for their shareholders. Giving out loans with higher risk of default shouldn’t be their responsibility, as it wouldn’t be fair to let the bank take the responsibility for high costs of medical care. I think that the burden of responsibility lies with the government. Healthcare shouldn’t be a for-profit industry, as profitability and health goals often do not align. Instead, what would be fair is if the government offered more healthcare benefits so people who needed medical procedures wouldn’t have to take out a loan."
  },
  {
    "objectID": "posts/blog-1/blog_1.html",
    "href": "posts/blog-1/blog_1.html",
    "title": "Blog One - Palmer Penguins",
    "section": "",
    "text": "image.png\n\n\n\n\nIn my blog post, I explore the best features to identify penguin species from the Palmer Penguins data set created by ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍Dr. Kristen Gorman ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍and ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍Palmer Station. I first explore the significance of some variables through data visualization, trying to glean key differences in penguin species, one of which appears to be island. Using a brute force search of all the possible combinations of one qualitative and two quantitative variables, I find that island, culmen length, and culmen depth are the three best features to predict the test set with 100% accuracy.\n\n\n\n\nimport pandas as pd\n\n# reading in the training data\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url) \n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nWe can see from the head of the training data some of the key variables to look at: island, clutch completion, culmen length/depth, flipper length and body mass. These variables jump out as the oens where we will likely see the biggest differences between species.\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"]) #encoding species\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1) #dropping uncessary variables\n  df = df[df[\"Sex\"] != \".\"] \n  df = df.dropna() #cleaning data\n  y = le.transform(df[\"Species\"]) #encoding species\n  df = df.drop([\"Species\"], axis = 1) \n  df = pd.get_dummies(df) \n  return df, y\n\n#creating test and train datasets\nX_train, y_train = prepare_data(train) \n\nIn the data preperation section, I prepare the data by dropping the variables that aren’t helpful for the analysis. I also use the label encoder function to encode the target variable (species). I also clean the data so I can prepare the features and the labels for training.\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"darkgrid\")\n\n\n## graph1 scatter + weight distribtuion\n\ndata= train\ngraph1 = sns.jointplot(data= data, x= \"Flipper Length (mm)\", y= \"Body Mass (g)\", hue = \"Species\")\nplt.show\n\n\n\n\n\n\n\n\nThe main takeaway I had from this graph is that flipper length is a great identifier for the Gentoo penguins, as they all have flipper lengths at about 208 mm or above, which is much longer than the average of an Adelie or a Chinstrap penguin. However, the body mass and flipper length are similar for and Chinstrap penguins, which means that they might not be the best identifier of a penguin. We can see that the distributions for body mass of the two species have almost complete overlap, with Adelie penguins having less devation in mass by penguin.\n\n# graph 2: catplot\ndata = train\ngraph2= sns.catplot(data= data, kind= \"swarm\", x= \"Island\", y=\"Culmen Length (mm)\", hue= \"Species\")\n\n\n\n\n\n\n\n\nThis visualization is very helpful for deciding which categories to model. The first thing I notice is that the Chinstrap and Gentoo species are native to one island and one island only (dream and biscoe, respectiveley). While the Adelie penguins appear on all 3 islands, they are the only ones that appear on Torgenrsen, so any penguin found on Torgersen should automatically be identified as a Adelie. Culmen length is also a good diffentiator,\n\ndata.groupby(\"Species\").aggregate({\"Flipper Length (mm)\" : \"mean\", \n                                   \"Culmen Length (mm)\" : \"mean\",\n                                    \"Culmen Depth (mm)\" : \"mean\",\n                                    \"Body Mass (g)\" : [\"mean\", \"min\", \"max\"]})\n\n\n\n\n\n\n\n\nFlipper Length (mm)\nCulmen Length (mm)\nCulmen Depth (mm)\nBody Mass (g)\n\n\n\nmean\nmean\nmean\nmean\nmin\nmax\n\n\nSpecies\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\n190.084034\n38.970588\n18.409244\n3718.487395\n2850.0\n4725.0\n\n\nChinstrap penguin (Pygoscelis antarctica)\n196.000000\n48.826316\n18.366667\n3743.421053\n2700.0\n4800.0\n\n\nGentoo penguin (Pygoscelis papua)\n216.752577\n47.073196\n14.914433\n5039.948454\n3950.0\n6300.0\n\n\n\n\n\n\n\nThis table shows clear distinctions between the penguins for the different quantitative variables highlighted here. For example, while Adelie and Chinstraps have similar flipper lengths, masses, and culmen depths, they vary vastly in clumen length. Gentoos can be differentiated through their much larger average body mass and longer flippers. There shouild be very little overlap betrween Adelie and Gentoo, as they very significantly on the different quantitative variables.\n\n\n\n\n%%capture\nfrom itertools import combinations\nfrom sklearn.linear_model import LogisticRegression\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Island\", \"Stage\", \"Sex\"] \nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', \"Body Mass (g)\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\" ]\n\nbest_score= 0\nfor qual in all_qual_cols: #iterating through all possible combinations of columns\n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2): \n    cols = list(pair) + qual_cols\n    #print(cols)\n    LR = LogisticRegression()\n    LR.fit(X_train[cols], y_train) #fitting the model\n    score = LR.score(X_train[cols], y_train) #scoring the model\n    if score &gt; best_score: #saving the best score\n      best_score = score\n      best_cols = cols\n    # you could train models and score them here, keeping the list of \n    # columns for the model that has the best score. \n\nThe way I approach selecting the best features is to use a nested loop to run through all possible combinations of one qualitative and two quantitative variables. I keep track of the training model with the best score and save those features.\n\n%%capture\nLR = LogisticRegression()\nLR.fit(X_train[best_cols], y_train) #running the model on the best features\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nHere I run the training model on my best selected features and load in the test data.\n\n#preparing the test set and testing it\nX_test, y_test = prepare_data(test)\nLR.score(X_test[best_cols], y_test)\n\n1.0\n\n\nI calculate the score here for the model established on the testing data and get an accuracy score of 100%.\n\n\n\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nprint(best_cols)\n\n\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n\n\n\n# plotting the decision reigon plot\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\n\nplot_regions(LR, X_train[best_cols], y_train)\nplot_regions(LR, X_test[best_cols], y_test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, we see the decision plots for the training and the testing data sets. As we saw in the explore section, certain species are native to certain islands. In the trainig data, we see that some Chinstrap penguins are on the boundary between Chinstrap and Gentoo reigons (causing slight misclassification), but due to the subset of data in the testing set, none of these penguins are super close to the boarder, so everything is classified correctly.\n\nfrom sklearn.metrics import confusion_matrix\n\n# creating confusion matricies for the test and train datasets.\ny_test_pred = LR.predict(X_test[best_cols])\nConfusion_test = confusion_matrix(y_test, y_test_pred)\nprint(Confusion_test) \ny_train_pred = LR.predict(X_train[best_cols])\nConfusion_train = confusion_matrix(y_train, y_train_pred)\nprint(Confusion_train)\n\n[[31  0  0]\n [ 0 11  0]\n [ 0  0 26]]\n[[108   0   0]\n [  1  55   0]\n [  0   0  92]]\n\n\nSince there are no errors in the test set, the first confusion matrix is diagonalizable. There are no penguins that are classified incorrectly. Because of this, I also created the same matrix for the train dataset, where one Chinstrap penguin was classified an Adelie. I wonder if this could be in part because the number of penguins in each set where drastically different, and since there a lot more Adelie I wonder if penguins were more likely to be classified as such.\n\n\n\nMy key takeaway from the analysis is that when using one feature on it’s own, or a pair of correlating features only (i.e. culmen length and culmen depth), logistic regression is decently accurate. The more features you pair together, the more accurate the logistic regression becomes, although the computing power escalates quickly. Island is a great quantitative identifier for penguins, as shown in figure 2 because Chinstraps and Gentoos exist only on different islands, so there is no overlap or mispredicting.\nOn competing my first blog post, I found the process very rewarding. I like being able to write out my ideas and complete my analysis all in the same document. I haven’t coded in a while, so debugging at first was difficult, but it got easier as I went on. I learned that, with both the coding and the discussion, it’s often best to step away for a bit and come back to the work with fresh eyes. That helped me when I was looking for significance in the explore step, and throughout debugging my model and the ensuing discussion."
  },
  {
    "objectID": "posts/blog-1/blog_1.html#abstract",
    "href": "posts/blog-1/blog_1.html#abstract",
    "title": "Blog One - Palmer Penguins",
    "section": "",
    "text": "In my blog post, I explore the best features to identify penguin species from the Palmer Penguins data set created by ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍Dr. Kristen Gorman ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍and ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍the ‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍Palmer Station. I first explore the significance of some variables through data visualization, trying to glean key differences in penguin species, one of which appears to be island. Using a brute force search of all the possible combinations of one qualitative and two quantitative variables, I find that island, culmen length, and culmen depth are the three best features to predict the test set with 100% accuracy."
  },
  {
    "objectID": "posts/blog-1/blog_1.html#setup",
    "href": "posts/blog-1/blog_1.html#setup",
    "title": "Blog One - Palmer Penguins",
    "section": "",
    "text": "import pandas as pd\n\n# reading in the training data\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url) \n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\nWe can see from the head of the training data some of the key variables to look at: island, clutch completion, culmen length/depth, flipper length and body mass. These variables jump out as the oens where we will likely see the biggest differences between species."
  },
  {
    "objectID": "posts/blog-1/blog_1.html#data-preperation",
    "href": "posts/blog-1/blog_1.html#data-preperation",
    "title": "Blog One - Palmer Penguins",
    "section": "",
    "text": "from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"]) #encoding species\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1) #dropping uncessary variables\n  df = df[df[\"Sex\"] != \".\"] \n  df = df.dropna() #cleaning data\n  y = le.transform(df[\"Species\"]) #encoding species\n  df = df.drop([\"Species\"], axis = 1) \n  df = pd.get_dummies(df) \n  return df, y\n\n#creating test and train datasets\nX_train, y_train = prepare_data(train) \n\nIn the data preperation section, I prepare the data by dropping the variables that aren’t helpful for the analysis. I also use the label encoder function to encode the target variable (species). I also clean the data so I can prepare the features and the labels for training."
  },
  {
    "objectID": "posts/blog-1/blog_1.html#explore",
    "href": "posts/blog-1/blog_1.html#explore",
    "title": "Blog One - Palmer Penguins",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"darkgrid\")\n\n\n## graph1 scatter + weight distribtuion\n\ndata= train\ngraph1 = sns.jointplot(data= data, x= \"Flipper Length (mm)\", y= \"Body Mass (g)\", hue = \"Species\")\nplt.show\n\n\n\n\n\n\n\n\nThe main takeaway I had from this graph is that flipper length is a great identifier for the Gentoo penguins, as they all have flipper lengths at about 208 mm or above, which is much longer than the average of an Adelie or a Chinstrap penguin. However, the body mass and flipper length are similar for and Chinstrap penguins, which means that they might not be the best identifier of a penguin. We can see that the distributions for body mass of the two species have almost complete overlap, with Adelie penguins having less devation in mass by penguin.\n\n# graph 2: catplot\ndata = train\ngraph2= sns.catplot(data= data, kind= \"swarm\", x= \"Island\", y=\"Culmen Length (mm)\", hue= \"Species\")\n\n\n\n\n\n\n\n\nThis visualization is very helpful for deciding which categories to model. The first thing I notice is that the Chinstrap and Gentoo species are native to one island and one island only (dream and biscoe, respectiveley). While the Adelie penguins appear on all 3 islands, they are the only ones that appear on Torgenrsen, so any penguin found on Torgersen should automatically be identified as a Adelie. Culmen length is also a good diffentiator,\n\ndata.groupby(\"Species\").aggregate({\"Flipper Length (mm)\" : \"mean\", \n                                   \"Culmen Length (mm)\" : \"mean\",\n                                    \"Culmen Depth (mm)\" : \"mean\",\n                                    \"Body Mass (g)\" : [\"mean\", \"min\", \"max\"]})\n\n\n\n\n\n\n\n\nFlipper Length (mm)\nCulmen Length (mm)\nCulmen Depth (mm)\nBody Mass (g)\n\n\n\nmean\nmean\nmean\nmean\nmin\nmax\n\n\nSpecies\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\n190.084034\n38.970588\n18.409244\n3718.487395\n2850.0\n4725.0\n\n\nChinstrap penguin (Pygoscelis antarctica)\n196.000000\n48.826316\n18.366667\n3743.421053\n2700.0\n4800.0\n\n\nGentoo penguin (Pygoscelis papua)\n216.752577\n47.073196\n14.914433\n5039.948454\n3950.0\n6300.0\n\n\n\n\n\n\n\nThis table shows clear distinctions between the penguins for the different quantitative variables highlighted here. For example, while Adelie and Chinstraps have similar flipper lengths, masses, and culmen depths, they vary vastly in clumen length. Gentoos can be differentiated through their much larger average body mass and longer flippers. There shouild be very little overlap betrween Adelie and Gentoo, as they very significantly on the different quantitative variables."
  },
  {
    "objectID": "posts/blog-1/blog_1.html#model",
    "href": "posts/blog-1/blog_1.html#model",
    "title": "Blog One - Palmer Penguins",
    "section": "",
    "text": "%%capture\nfrom itertools import combinations\nfrom sklearn.linear_model import LogisticRegression\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Island\", \"Stage\", \"Sex\"] \nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', \"Body Mass (g)\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\" ]\n\nbest_score= 0\nfor qual in all_qual_cols: #iterating through all possible combinations of columns\n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2): \n    cols = list(pair) + qual_cols\n    #print(cols)\n    LR = LogisticRegression()\n    LR.fit(X_train[cols], y_train) #fitting the model\n    score = LR.score(X_train[cols], y_train) #scoring the model\n    if score &gt; best_score: #saving the best score\n      best_score = score\n      best_cols = cols\n    # you could train models and score them here, keeping the list of \n    # columns for the model that has the best score. \n\nThe way I approach selecting the best features is to use a nested loop to run through all possible combinations of one qualitative and two quantitative variables. I keep track of the training model with the best score and save those features.\n\n%%capture\nLR = LogisticRegression()\nLR.fit(X_train[best_cols], y_train) #running the model on the best features\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nHere I run the training model on my best selected features and load in the test data.\n\n#preparing the test set and testing it\nX_test, y_test = prepare_data(test)\nLR.score(X_test[best_cols], y_test)\n\n1.0\n\n\nI calculate the score here for the model established on the testing data and get an accuracy score of 100%."
  },
  {
    "objectID": "posts/blog-1/blog_1.html#evaluate",
    "href": "posts/blog-1/blog_1.html#evaluate",
    "title": "Blog One - Palmer Penguins",
    "section": "",
    "text": "from matplotlib import pyplot as plt\nimport numpy as np\nprint(best_cols)\n\n\n['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\n\n\n\n# plotting the decision reigon plot\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\n\nplot_regions(LR, X_train[best_cols], y_train)\nplot_regions(LR, X_test[best_cols], y_test)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere, we see the decision plots for the training and the testing data sets. As we saw in the explore section, certain species are native to certain islands. In the trainig data, we see that some Chinstrap penguins are on the boundary between Chinstrap and Gentoo reigons (causing slight misclassification), but due to the subset of data in the testing set, none of these penguins are super close to the boarder, so everything is classified correctly.\n\nfrom sklearn.metrics import confusion_matrix\n\n# creating confusion matricies for the test and train datasets.\ny_test_pred = LR.predict(X_test[best_cols])\nConfusion_test = confusion_matrix(y_test, y_test_pred)\nprint(Confusion_test) \ny_train_pred = LR.predict(X_train[best_cols])\nConfusion_train = confusion_matrix(y_train, y_train_pred)\nprint(Confusion_train)\n\n[[31  0  0]\n [ 0 11  0]\n [ 0  0 26]]\n[[108   0   0]\n [  1  55   0]\n [  0   0  92]]\n\n\nSince there are no errors in the test set, the first confusion matrix is diagonalizable. There are no penguins that are classified incorrectly. Because of this, I also created the same matrix for the train dataset, where one Chinstrap penguin was classified an Adelie. I wonder if this could be in part because the number of penguins in each set where drastically different, and since there a lot more Adelie I wonder if penguins were more likely to be classified as such."
  },
  {
    "objectID": "posts/blog-1/blog_1.html#discussion",
    "href": "posts/blog-1/blog_1.html#discussion",
    "title": "Blog One - Palmer Penguins",
    "section": "",
    "text": "My key takeaway from the analysis is that when using one feature on it’s own, or a pair of correlating features only (i.e. culmen length and culmen depth), logistic regression is decently accurate. The more features you pair together, the more accurate the logistic regression becomes, although the computing power escalates quickly. Island is a great quantitative identifier for penguins, as shown in figure 2 because Chinstraps and Gentoos exist only on different islands, so there is no overlap or mispredicting.\nOn competing my first blog post, I found the process very rewarding. I like being able to write out my ideas and complete my analysis all in the same document. I haven’t coded in a while, so debugging at first was difficult, but it got easier as I went on. I learned that, with both the coding and the discussion, it’s often best to step away for a bit and come back to the work with fresh eyes. That helped me when I was looking for significance in the explore step, and throughout debugging my model and the ensuing discussion."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Blog Two - Design and Impact of Automated Decision Systems\n\n\n\n\n\nBank Loaning\n\n\n\n\n\nFeb 27, 2025\n\n\nChloe Katz\n\n\n\n\n\n\n\n\n\n\n\n\nBlog One - Palmer Penguins\n\n\n\n\n\nPalmer Penguins\n\n\n\n\n\nFeb 16, 2025\n\n\nChloe Katz\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  }
]